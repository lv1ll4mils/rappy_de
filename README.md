# Proyecto: Snowflake Data Pipeline with Airflow & S3

## Este proyecto implementa un pipeline de datos con:

- Apache Airflow
- Snowflake
- Amazon S3
- Kaggle
- Slack Webhooks


## âœ… Flujo de trabajo
- Descarga dataset desde Kaggle.
- Carga los CSV en Snowflake (RAW_DATA).
- Crea nuevas tablas en TRANSFORM_DATA usando SQL.
- Ejecuta consultas y exporta resultados a S3.
- EnvÃ­a notificaciones a Slack al finalizar cada tarea.


```
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ load_process.py              # DAG principal
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ callbacks.py             # Slack alerts
â”‚       â”œâ”€â”€ snowflake_conn.py        # ConexiÃ³n a Snowflake
â”‚       â”œâ”€â”€ s3_conn.py               # ConexiÃ³n a S3
â”‚       â””â”€â”€ task_executor.py         # Ejecuta funciones con logging
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ load_dataset_snowflake.py    # Carga de datos a Snowflake
â”‚   â””â”€â”€ export_to_s3.py              # Exporta resultado a S3
â”‚
â”œâ”€â”€ include/
â”‚   â””â”€â”€ sql/
â”‚       â”œâ”€â”€ create_tables.sql        # SQL para crear tablas
â”‚       â””â”€â”€ export_queries.sql       # SQL para hacer selects
```


## âš™ï¸ Requisitos
- Python 3.8+
- Airflow 2.x
- Cuenta de Snowflake
- Cuenta de AWS (S3)
- Cuenta de Kaggle + API Key

### Guardar tu archivo kaggle.json en:
- project-root/.secrets/kaggle.json


### ğŸ”” Notificaciones
**Slack envÃ­a alertas en:**

- âœ… Ã‰xito
- âŒ Error

**No olvide crear una Slack Webhook URL para poder enviar mensajes desde Airflow a un canal:**

- 1. Ingrese a https://api.slack.com/apps
- 2. Clic en Create App
- 3. ActivÃ¡ la opciÃ³n que indica "Activate Incoming Webhooks"
- 4. Clic en "Add New Webhook to Workspace" y continue con los demas pasos.

![alt text](msn_slack.png)


# ğŸ“„ Licencia
- MIT â€” libre de usar y adaptar.


# ğŸ‘¨â€ğŸ’» Autor
Luiyerfreht Villamil\
Data Engineer | Python | Cloud\
GitHub